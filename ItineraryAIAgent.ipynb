{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b3b9050",
        "outputId": "5c50fb1e-9fb0-4e34-f524-4049990be2a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.1/131.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain langchain_core langchain_groq langgraph gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "964c38cc"
      },
      "outputs": [],
      "source": [
        "from typing import TypedDict, Annotated, List\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "import gradio as gr\n",
        "\n",
        "# Set up LLM\n",
        "llm = ChatGroq(\n",
        "    temperature=0,\n",
        "    groq_api_key=\"Enter here\",  # Replace with your key\n",
        "    model_name=\"llama-3.3-70b-versatile\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "505b26a8"
      },
      "outputs": [],
      "source": [
        "class PlannerState(TypedDict):\n",
        "    messages: Annotated[List[HumanMessage | AIMessage], \"Conversation history\"]\n",
        "    city: str\n",
        "    interests: List[str]\n",
        "    weather: str\n",
        "    places: List[str]\n",
        "    itinerary: str\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ae788b1c"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "def get_weather(city: str) -> str:\n",
        "    # Get lat/lon from city using geocoding API\n",
        "    geo_url = f\"https://geocoding-api.open-meteo.com/v1/search?name={city}&count=1\"\n",
        "    geo_resp = requests.get(geo_url)\n",
        "    geo_data = geo_resp.json()\n",
        "\n",
        "    if \"results\" not in geo_data or not geo_data[\"results\"]:\n",
        "        return f\"Couldn't find weather info for {city}.\"\n",
        "\n",
        "    location = geo_data[\"results\"][0]\n",
        "    lat, lon = location[\"latitude\"], location[\"longitude\"]\n",
        "\n",
        "    # Fetch weather using weather API\n",
        "    weather_url = f\"https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={lon}&current_weather=true\"\n",
        "    weather_resp = requests.get(weather_url)\n",
        "    weather_data = weather_resp.json()\n",
        "\n",
        "    current = weather_data.get(\"current_weather\", {})\n",
        "    if not current:\n",
        "        return f\"Couldn't retrieve weather data for {city}.\"\n",
        "\n",
        "    temp = current[\"temperature\"]\n",
        "    wind = current[\"windspeed\"]\n",
        "    desc = f\"{temp}°C with wind speeds of {wind} m/s\"\n",
        "\n",
        "    return f\"The weather in {city} is currently {desc}.\"\n",
        "\n",
        "def search_places(city: str, interests: List[str]) -> List[str]:\n",
        "    sample_places = {\n",
        "        \"museum\": f\"{city} Art Museum\",\n",
        "        \"park\": f\"{city} Central Park\",\n",
        "        \"coffee\": f\"{city} Roasters Cafe\",\n",
        "        \"nature\": f\"{city} Botanical Gardens\"\n",
        "    }\n",
        "    matched = []\n",
        "    for interest in interests:\n",
        "        for key, place in sample_places.items():\n",
        "            if key in interest.lower():\n",
        "                matched.append(place)\n",
        "    return matched or [f\"Explore local attractions in {city}.\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5f473d8"
      },
      "outputs": [],
      "source": [
        "def generate_itinerary(state: PlannerState) -> PlannerState:\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"You are a helpful travel assistant. The user is visiting {city}. The weather is: {weather}. Their interests include: {interests}. Provide a concise, bulleted day trip itinerary that takes the weather into account.\"),\n",
        "        (\"human\", \"Create my day trip itinerary.\")\n",
        "    ])\n",
        "\n",
        "    messages = prompt.format_messages(\n",
        "        city=state[\"city\"],\n",
        "        interests=\", \".join(state[\"interests\"]),\n",
        "        weather=state[\"weather\"]\n",
        "    )\n",
        "\n",
        "    response = llm.invoke(messages)\n",
        "    state[\"itinerary\"] = response.content\n",
        "    state[\"messages\"].append(AIMessage(content=response.content))\n",
        "    return state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "920c4510"
      },
      "outputs": [],
      "source": [
        "def input_handler(state: PlannerState) -> PlannerState:\n",
        "    return state\n",
        "\n",
        "def fetch_weather(state: PlannerState) -> PlannerState:\n",
        "    weather = get_weather(state['city'])\n",
        "    state['weather'] = weather\n",
        "    state['messages'].append(AIMessage(content=f\"Weather: {weather}\"))\n",
        "    return state\n",
        "\n",
        "def find_places(state: PlannerState) -> PlannerState:\n",
        "    places = search_places(state['city'], state['interests'])\n",
        "    state['places'] = places\n",
        "    state['messages'].append(AIMessage(content=f\"Places of interest: {', '.join(places)}\"))\n",
        "    return state\n",
        "\n",
        "def generate_itinerary(state: PlannerState) -> PlannerState:\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"You are a helpful travel assistant. The user is visiting {city}. The weather is: {weather}. Their interests include: {interests}. Provide a concise, bulleted day trip itinerary that takes the weather into account.\"),\n",
        "        (\"human\", \"Create my day trip itinerary.\")\n",
        "    ])\n",
        "\n",
        "    messages = prompt.format_messages(\n",
        "        city=state[\"city\"],\n",
        "        interests=\", \".join(state[\"interests\"]),\n",
        "        weather=state[\"weather\"]\n",
        "    )\n",
        "\n",
        "    response = llm.invoke(messages)\n",
        "    state[\"itinerary\"] = response.content\n",
        "    state[\"messages\"].append(AIMessage(content=response.content))\n",
        "    return state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5476228"
      },
      "outputs": [],
      "source": [
        "graph = StateGraph(PlannerState)\n",
        "graph.add_node(\"InputHandler\", input_handler)\n",
        "graph.add_node(\"FetchWeather\", fetch_weather)\n",
        "graph.add_node(\"FindPlaces\", find_places)\n",
        "graph.add_node(\"GenerateItinerary\", generate_itinerary)\n",
        "\n",
        "graph.set_entry_point(\"InputHandler\")\n",
        "graph.add_edge(\"InputHandler\", \"FetchWeather\")\n",
        "graph.add_edge(\"FetchWeather\", \"FindPlaces\")\n",
        "graph.add_edge(\"FindPlaces\", \"GenerateItinerary\")\n",
        "graph.add_edge(\"GenerateItinerary\", END)\n",
        "\n",
        "app = graph.compile()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "038a1565",
        "outputId": "95f37259-2d37-4e96-dff3-c9beb01d9fca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a518e44354267d4c75.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a518e44354267d4c75.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "def travel_planner_agent(city: str, interests: str) -> str:\n",
        "    initial_state = {\n",
        "        \"messages\": [],\n",
        "        \"city\": city,\n",
        "        \"interests\": [i.strip() for i in interests.split(\",\")],\n",
        "        \"weather\": \"\",\n",
        "        \"places\": [],\n",
        "        \"itinerary\": \"\"\n",
        "    }\n",
        "    final_state = app.invoke(initial_state)\n",
        "    return final_state[\"itinerary\"]\n",
        "\n",
        "gr.Interface(\n",
        "    fn=travel_planner_agent,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Enter your city\"),\n",
        "        gr.Textbox(label=\"Enter interests (comma-separated)\")\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Your personalized itinerary\"),\n",
        "    title=\"AI Travel Agent (LangGraph)\",\n",
        "    description=\"Plans a custom day trip using reasoning and tool use\"\n",
        ").launch()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}